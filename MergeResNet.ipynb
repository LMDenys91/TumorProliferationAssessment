{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from keras.layers import merge\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Nadam\n",
    "from keras.metrics import MSE\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ProgbarLogger, ModelCheckpoint\n",
    "from keras.layers import Input\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "from scipy.stats import spearmanr\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import scandir\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from ml_metrics import quadratic_weighted_kappa\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['CUDA_HOME'] = '/usr/local/cuda-7.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_img(img_path):\n",
    "    '''This function returns a preprocessed image\n",
    "    '''\n",
    "    dim_ordering = K.image_dim_ordering()\n",
    "    img = load_img(img_path, target_size=(512, 512))\n",
    "    img = img_to_array(img, dim_ordering=dim_ordering)\n",
    "\n",
    "    if dim_ordering == 'th':\n",
    "        img = img[::-1, :, :]\n",
    "    else:\n",
    "        img = img[:, :, ::-1]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block, idx):\n",
    "    '''The identity_block is the block that has no conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    '''\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch' + '_' + 'idx'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch' + '_' + 'idx'\n",
    "\n",
    "    x = Convolution2D(nb_filter1, 1, 1, name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter2, kernel_size, kernel_size,\n",
    "                      border_mode='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = merge([x, input_tensor], mode='sum')\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, idx, strides=(2, 2)):\n",
    "    '''conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "    And the shortcut should have subsample=(2,2) as well\n",
    "    '''\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch' + '_' + 'idx'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch' + '_' + 'idx'\n",
    "\n",
    "    x = Convolution2D(nb_filter1, 1, 1, subsample=strides,\n",
    "                      name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter2, kernel_size, kernel_size, border_mode='same',\n",
    "                      name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Convolution2D(nb_filter3, 1, 1, subsample=strides,\n",
    "                             name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = merge([x, shortcut], mode='sum')\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: spatial parameters\n",
    "def ResNet50(inp=None, idx=0):\n",
    "    '''Adapted from https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py'''\n",
    "    # Determine proper input shape\n",
    "    \n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        inp_shape=(512, 512, 3)\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        inp_shape=(3, 512, 512)\n",
    "        bn_axis = 1\n",
    "    dim_ordering = K.image_dim_ordering()\n",
    "\n",
    "    inp = Input(inp_shape)\n",
    "    with tf.device('/gpu:0'):          \n",
    "        x = Convolution2D(64, 7, 7, subsample=(3, 3),\n",
    "                            init='he_normal', border_mode='same', dim_ordering=dim_ordering,\n",
    "                            name='conv1_{0}'.format(idx), input_shape=(inp_shape))(inp)\n",
    "        x = BatchNormalization(axis=bn_axis, name='bn_conv1_{0}'.format(idx))(x)\n",
    "        x = Activation('relu')(x) #LeakyReLU(alpha=0.5)\n",
    "        x = MaxPooling2D((3, 3), strides=(2, 2), dim_ordering=dim_ordering)(x)\n",
    "\n",
    "        x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', idx=idx, strides=(1, 1))\n",
    "        x = identity_block(x, 3, [64, 64, 256], stage=2, block='b', idx=idx)\n",
    "        x = identity_block(x, 3, [64, 64, 256], stage=2, block='c', idx=idx)\n",
    "\n",
    "    with tf.device('/gpu:1'):\n",
    "        x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', idx=idx)\n",
    "        x = identity_block(x, 3, [128, 128, 512], stage=3, block='b', idx=idx)\n",
    "        x = identity_block(x, 3, [128, 128, 512], stage=3, block='c', idx=idx)\n",
    "        x = identity_block(x, 3, [128, 128, 512], stage=3, block='d', idx=idx)\n",
    "\n",
    "    with tf.device('/gpu:2'):\n",
    "        x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', idx=idx)\n",
    "        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b', idx=idx)\n",
    "        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c', idx=idx)\n",
    "        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d', idx=idx)\n",
    "        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e', idx=idx)\n",
    "        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f', idx=idx)\n",
    "\n",
    "    with tf.device('/gpu:3'):\n",
    "        x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a', idx=idx)\n",
    "        x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b', idx=idx)\n",
    "        x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c', idx=idx)\n",
    "\n",
    "        x = AveragePooling2D((7, 7), name='avg_pool_{0}'.format(idx))(x)\n",
    "\n",
    "    return Model(inp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches_per_slice = 5\n",
    "def get_mergenet():    \n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        inp_shape=(512, 512, 3)\n",
    "        concat_axis = 3\n",
    "    else:\n",
    "        inp_shape=(3, 512, 512)\n",
    "        concat_axis = 1\n",
    "    \n",
    "    patch_nets = []\n",
    "    input_list = []\n",
    "    for i in range(patches_per_slice):\n",
    "        inp = Input(inp_shape)\n",
    "        model = ResNet50(inp, i)\n",
    "        patch_nets.append(model)\n",
    "        input_list.append(inp)\n",
    "        \n",
    "    out = merge(patch_nets, mode='ave')#, concat_axis=concat_axis)\n",
    "    out = Flatten()(out)\n",
    "    out = Dense(2, activation='softmax', name='fc')(out)\n",
    "    return Model(input_list, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Started to build model at {0}'.format(datetime.datetime.utcnow()))\n",
    "model = get_mergenet()\n",
    "model.summary()\n",
    "print('Finished building model at {0}'.format(datetime.datetime.utcnow()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: insert my own loss and metrics functions (one per output), equal to the ones specified by TUPAC\n",
    "print('Started to compile model at {0}'.format(datetime.datetime.utcnow()))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mse'])\n",
    "print('Finished compiling model at {0}'.format(datetime.datetime.utcnow()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(dir_path, res = 512):\n",
    "    annotations = open('../annotations/training_ground_truth.csv', 'r')\n",
    "    lines = annotations.readlines()\n",
    "    images = []\n",
    "    labels = []\n",
    "    for subdir, _, files in scandir.walk(dir_path):\n",
    "        subdir = subdir.replace('\\\\', '/')  # windows path fix\n",
    "        subdir_split = subdir.split('/')\n",
    "        if len(subdir_split[3])>0: study_id = int(subdir_split[3].lstrip(\"0\"))\n",
    "        else: continue\n",
    "        label = [float(lines[study_id].split(',')[0]), float(lines[study_id].split(',')[1])]\n",
    "        imgs = []\n",
    "        for f in files:\n",
    "            tiff_path = os.path.join(subdir, f)\n",
    "            if not tiff_path.endswith('.tiff'):\n",
    "                continue\n",
    "            img = read_img(tiff_path)\n",
    "            imgs.append(img)\n",
    "        images.append(imgs)\n",
    "        labels.append(label)\n",
    "    annotations.close()\n",
    "    images_list = []\n",
    "    for x in np.split(np.swapaxes(images, 0, 1), patches_per_slice):\n",
    "        images_list.append(np.squeeze(x))\n",
    "    return images_list, np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "images_train, labels_train = get_data('../example_images/train/')\n",
    "images_val, labels_val = get_data('../example_images/val/')\n",
    "print(images_train[0].shape, len(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# featurewise standardization, normalization and augmentation (horizontal and vertical flips)\n",
    "def augment_data(X):\n",
    "    X = np.asarray(X).swapaxes(1, 0)\n",
    "    mean = np.mean(X, axis=0)\n",
    "    X -= mean\n",
    "    std = np.std(X, axis=0)\n",
    "    X /= (std + 1e-7)\n",
    "    X = X.swapaxes(0, 1)\n",
    "    if np.random.random() < 0.5:\n",
    "        X = flip_axis(X, 2)\n",
    "    if np.random.random() < 0.5:\n",
    "        X = flip_axis(X, 3)\n",
    "    return X\n",
    "        \n",
    "def flip_axis(X, axis):\n",
    "    X = np.asarray(X).swapaxes(axis, 0)\n",
    "    X = X[::-1, ...]\n",
    "    X = X.swapaxes(0, axis)\n",
    "    return X\n",
    "\n",
    "print('Started data augmentation at {0}'.format(datetime.datetime.utcnow()))\n",
    "images_train = augment_data(images_train)\n",
    "images_val = augment_data(images_val)\n",
    "print('Finished data augmentation at {0}'.format(datetime.datetime.utcnow()))\n",
    "#print(np.mean(images_train[0]), np.std(images_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "nb_epoch = 10\n",
    "patches_per_slice = 5\n",
    "#class_weights = {}\n",
    "callbacks = [ProgbarLogger(),\n",
    "             ModelCheckpoint('mergenet_weights.hdf5', monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True, mode='auto')]\n",
    "\n",
    "print('Started fitting at {0}'.format(datetime.datetime.utcnow()))\n",
    "history = model.fit(images_train, labels_train, batch_size,\n",
    "                              #samples_per_epoch=images_train.shape[0],\n",
    "                              #class_weights = class_weights,\n",
    "                              nb_epoch=nb_epoch, verbose=1,\n",
    "                              validation_data=(images_val, labels_val),\n",
    "                              #nb_val_samples = 1,\n",
    "                              callbacks=callbacks)\n",
    "print('Finished fitting at {0}'.format(datetime.datetime.utcnow()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decode predictions to one hot encoding\n",
    "# Use ranking approach from https://github.com/ChenglongChen/Kaggle_CrowdFlower/blob/master/BlogPost/BlogPost.md\n",
    "# The predicted values are mapped to classes based on the CDF of the ref values.\n",
    "hist = np.bincount(labels_train[:,0].astype(int))\n",
    "cdf = np.cumsum(hist) / float(sum(hist))\n",
    "np.savetxt(\"../example_images/train/cdf.txt\", cdf)\n",
    "\n",
    "def getScore(pred, cdf, valid=False):\n",
    "    num = pred.shape[0]\n",
    "    output = np.asarray([4]*num, dtype=int)\n",
    "    rank = pred.argsort()\n",
    "    output[rank[:int(num*cdf[0]-1)]] = 1\n",
    "    output[rank[int(num*cdf[0]):int(num*cdf[1]-1)]] = 2\n",
    "    output[rank[int(num*cdf[1]):int(num*cdf[2]-1)]] = 3\n",
    "    if valid:\n",
    "        cutoff = [ pred[rank[int(num*cdf[i]-1)]] for i in range(3) ]\n",
    "        return output, cutoff\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Metrics on validation set:\\n------------------------------------------------------------\\n')\n",
    "pred = model.predict(images_val, verbose=0)\n",
    "pred_class = getScore(pred[:,0], cdf)\n",
    "print('Confusion Matrix:\\n', confusion_matrix(labels_val[:,0], pred_class), '\\n')\n",
    "print(classification_report(labels_val[:,0], pred_class), '\\n')\n",
    "print(\"Quadratic Weighted Cohen's Kappa: \", quadratic_weighted_kappa(pred[:,0], labels_val[:,0]))\n",
    "print(\"Spearman's Correlation Coëfficient: \", spearmanr(pred[:,1], labels_val[:,1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
