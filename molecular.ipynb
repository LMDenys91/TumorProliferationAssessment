{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from __future__ import print_function\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import spearmanr\n",
    "import openslide as ops\n",
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import json\n",
    "from ml_metrics import quadratic_weighted_kappa\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "import keras.backend as K\n",
    "import scandir\n",
    "from sklearn import cross_validation\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import merge\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Dense, Activation, Flatten, MaxoutDense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['CUDA_HOME'] = '/usr/local/cuda-7.5'\n",
    "\n",
    "def read_img(img_path):\n",
    "    dim_ordering = K.image_dim_ordering()\n",
    "    img = load_img(img_path, target_size=(512, 512))\n",
    "    img = img_to_array(img, dim_ordering=dim_ordering)\n",
    "\n",
    "    if dim_ordering == 'th':\n",
    "        img = img[::-1, :, :]\n",
    "    else:\n",
    "        img = img[:, :, ::-1]\n",
    "    return img\n",
    "\n",
    "def splitAndSqueeze(images, patches_per_slice=3):\n",
    "    result = []\n",
    "    for img in np.split(images, patches_per_slice):\n",
    "        result.append(np.squeeze(img))\n",
    "    return result\n",
    "\n",
    "# featurewise standardization, normalization and augmentation (horizontal and vertical flips)\n",
    "def augment_data(X, patches_per_slice=3):\n",
    "    X = np.asarray(X).swapaxes(1, 0)\n",
    "    mean = np.mean(X, axis=0)\n",
    "    X = np.subtract(X, mean)\n",
    "    std = np.std(X, axis=0)\n",
    "    X /= (std + 1e-7)\n",
    "    X = X.swapaxes(0, 1)\n",
    "    if np.random.random() < 0.5:\n",
    "        X = flip_axis(X, 2)\n",
    "    if np.random.random() < 0.5:\n",
    "        X = flip_axis(X, 3)\n",
    "    return splitAndSqueeze(X)\n",
    "\n",
    "def flip_axis(X, axis):\n",
    "    X = np.asarray(X).swapaxes(axis, 0)\n",
    "    X = X[::-1, ...]\n",
    "    X = X.swapaxes(0, axis)\n",
    "    return X\n",
    "\n",
    "# Decode predictions to one hot encoding\n",
    "# Use ranking approach from https://github.com/ChenglongChen/Kaggle_CrowdFlower/blob/master/BlogPost/BlogPost.md\n",
    "# The predicted values are mapped to classes based on the CDF of the ref values.\n",
    "def getScore(pred, cdf, valid=False):\n",
    "    num = pred.shape[0]\n",
    "    output = np.asarray([3]*num, dtype=int)\n",
    "    rank = pred.argsort()\n",
    "    output[rank[:int(num*cdf[0]-1)]] = 1\n",
    "    output[rank[int(num*cdf[0]):int(num*cdf[1]-1)]] = 2\n",
    "    output[rank[int(num*cdf[1]):int(num*cdf[2]-1)]] = 3\n",
    "    if valid:\n",
    "        cutoff = [ pred[rank[int(num*cdf[i]-1)]] for i in range(3) ]\n",
    "        return output, cutoff\n",
    "    return output\n",
    "\n",
    "def plotLearningCurve(history):\n",
    "    plt.plot(history.history['mean_squared_error'])\n",
    "    #plt.plot(history.history['val_mean_squared_error'])\n",
    "    plt.title('Learning Curve')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.savefig('learning_curve_{0}.jpg'.format(datetime.datetime.utcnow()))\n",
    "\n",
    "# Since we are looking for very local features, we should need a short amount of layers(2?), followed by a FCN\n",
    "def get_patchblock(inp, idx):\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        inp_shape=(512, 512, 3)\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        inp_shape=shape=(3, 512, 512)\n",
    "        bn_axis = 1\n",
    "    dim_ordering = K.image_dim_ordering()\n",
    "\n",
    "    out = Convolution2D(32, 7, 7, subsample=(2, 2),\n",
    "                        init='he_normal', border_mode='same', dim_ordering=dim_ordering,\n",
    "                        name='conv1_{0}'.format(idx), input_shape=(inp_shape))(inp)\n",
    "    out = BatchNormalization(axis=bn_axis, name='bn_conv1_{0}'.format(idx))(out)\n",
    "    out = Activation('relu')(out) #LeakyReLU(alpha=0.5)\n",
    "    out = MaxPooling2D((3, 3), strides=(2, 2), dim_ordering=dim_ordering)(out)\n",
    "\n",
    "    out = Convolution2D(32, 3, 3, subsample=(2, 2),\n",
    "                        init='he_normal', border_mode='same', dim_ordering=dim_ordering,\n",
    "                        name='conv2_{0}'.format(idx), input_shape=(inp_shape))(out)\n",
    "    out = BatchNormalization(axis=bn_axis, name='bn_conv2_{0}'.format(idx))(out)\n",
    "    out = Activation('relu')(out) #LeakyReLU(alpha=0.5)\n",
    "    \n",
    "    out = Convolution2D(32, 3, 3, subsample=(2, 2),\n",
    "                        init='he_normal', border_mode='same', dim_ordering=dim_ordering,\n",
    "                        name='conv3_{0}'.format(idx), input_shape=(inp_shape))(out)\n",
    "    out = BatchNormalization(axis=bn_axis, name='bn_conv3_{0}'.format(idx))(out)\n",
    "    out = Activation('relu')(out) #LeakyReLU(alpha=0.5)\n",
    "\n",
    "    out = MaxPooling2D((3, 3), strides=(2, 2), dim_ordering=dim_ordering)(out)\n",
    "\n",
    "    out = Flatten()(out)\n",
    "    out = MaxoutDense(1, init='he_normal')(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def get_mergenet(patches_per_slice=3):\n",
    "    print('Started to build model at {0}'.format(datetime.datetime.utcnow()))\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        inp_shape=(512, 512, 3)\n",
    "        concat_axis = 3\n",
    "    else:\n",
    "        inp_shape=shape=(3, 512, 512)\n",
    "        concat_axis = 1\n",
    "\n",
    "    patch_nets = []\n",
    "    input_list = []\n",
    "    for i in range(patches_per_slice):\n",
    "        inp = Input(inp_shape)\n",
    "        model = get_patchblock(inp, i)\n",
    "        patch_nets.append(model)\n",
    "        input_list.append(inp)\n",
    "\n",
    "    out = merge(patch_nets, mode='ave')#, concat_axis=concat_axis)\n",
    "    out = MaxoutDense(1, init='he_normal')(out)\n",
    "    print('Finished building model at {0}'.format(datetime.datetime.utcnow()))\n",
    "    return Model(input_list, out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(dir_path, res = 512, limit=False):\n",
    "    annotations = open('../annotations/training_ground_truth.csv', 'r')\n",
    "    lines = annotations.readlines()\n",
    "    images_train = []\n",
    "    labels_train = []\n",
    "    images_val = []\n",
    "    labels_val = []\n",
    "    rs = cross_validation.ShuffleSplit(len(lines), n_iter = 1, test_size = 0.2, random_state = 17)\n",
    "    val_idx = []\n",
    "    count = 0\n",
    "    for train_index, val_index in rs:\n",
    "        val_idx.append(val_index)\n",
    "    for subdir, _, files in scandir.walk(dir_path):\n",
    "        for file in files:\n",
    "            study_id = int(file[9:12].lstrip(\"0\"))\n",
    "            label = [float(lines[study_id-1].split(',')[0]), float(lines[study_id-1].split(',')[1])]\n",
    "            imgs = get_images(file[9:12])\n",
    "            if len(imgs)<3: continue\n",
    "            if (study_id in val_idx[0]):\n",
    "                images_val.append(np.asarray(imgs))\n",
    "                labels_val.append(np.asarray(label))\n",
    "            else:\n",
    "                images_train.append(np.asarray(imgs))\n",
    "                labels_train.append(np.asarray(label))\n",
    "            count += 1\n",
    "            if limit and count >=10:\n",
    "                break\n",
    "        if limit and count >=10:\n",
    "                break\n",
    "    annotations.close()\n",
    "    images_train = splitAndSqueeze(np.swapaxes(np.asarray(images_train), 0, 1))\n",
    "    images_val = splitAndSqueeze(np.swapaxes(np.asarray(images_val), 0, 1))\n",
    "    return images_train, images_val, np.asarray(labels_train), np.asarray(labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_images(study_id, svs_dir='../../images/train/', roi_dir='../ROIs/'):\n",
    "    rois = open(roi_dir+'TUPAC-TR-{0}-ROI.csv'.format(study_id), 'r').readlines()\n",
    "    try:\n",
    "        slide = ops.OpenSlide(svs_dir+'{0}/{1}.svs'.format(study_id, study_id))\n",
    "    except ops.OpenSlideUnsupportedFormatError:\n",
    "        print('Not able to open svs file at: {0}'.format(svs_dir+'{0}/{1}.svs'.format(study_id, study_id)))\n",
    "        return []\n",
    "    imgs = []\n",
    "    for roi in rois:\n",
    "        roi = roi.split(',')\n",
    "        centroid = [int(roi[0])+int(math.ceil(int(roi[2])/2)), int(roi[1])+int(math.ceil(int(roi[3])/2))]\n",
    "        try:\n",
    "            level = 2\n",
    "            img = np.asarray(slide.read_region((centroid[0]-512, centroid[1]-512), 0, [1024, 1024]))\n",
    "        except ops.OpenSlideError:\n",
    "            print('Not able to open slide', study_id)\n",
    "            return []\n",
    "        res = 512\n",
    "        img = cv2.resize(img, (res, res), interpolation = cv2.INTER_AREA)\n",
    "        img = img[:, :, 0:3]\n",
    "        dim_ordering = K.image_dim_ordering()\n",
    "        img = img_to_array(img, dim_ordering=dim_ordering)\n",
    "        if dim_ordering == 'th':\n",
    "            img = img[::-1, :, :]\n",
    "        else:\n",
    "            img = img[:, :, ::-1]\n",
    "        imgs.append(img)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patches_per_slice = 3\n",
    "model = get_mergenet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def spearmanloss(y_true, y_pred, batch_size=50):\n",
    "    length = batch_size\n",
    "    original_loss = -1*length*tf.reduce_sum(tf.mul(y_true, y_pred))-(tf.reduce_sum(y_true)*tf.reduce_sum(y_pred))\n",
    "    divisor = tf.sqrt((length * tf.reduce_sum(tf.square(y_true)) - tf.square(tf.reduce_sum(y_true))) *\n",
    "                      (length * tf.reduce_sum(tf.square(y_pred)) - tf.square(tf.reduce_sum(y_pred)))\n",
    "                     )\n",
    "    return tf.truediv(original_loss, divisor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = 'adam'#SGD(lr=0.1)\n",
    "model.compile(optimizer=opt,loss='mse',metrics=['mse'])\n",
    "images_train, images_val, labels_train, labels_val = get_data('../ROIs/')#, limit=True)\n",
    "print(np.asarray(images_train).shape)\n",
    "images_train = augment_data(images_train)\n",
    "images_val = augment_data(images_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "nb_epoch = 30\n",
    "callbacks = [ModelCheckpoint('mergenet_weights{0}.hdf5'.format(datetime.datetime.utcnow()), monitor='val_loss', verbose=1,\n",
    "                         save_best_only=True, mode='auto')]\n",
    "print('Started fitting at {0}'.format(datetime.datetime.utcnow()))\n",
    "history = model.fit(images_train, labels_train[:,1], batch_size,\n",
    "                          nb_epoch=nb_epoch, verbose=1,\n",
    "                          validation_data=(images_val, labels_val[:,1]),\n",
    "                          callbacks=callbacks, shuffle=True)\n",
    "print('Finished fitting at {0}'.format(datetime.datetime.utcnow()))\n",
    "with open('01_mergenet_training_history{0}.json'.format(datetime.datetime.utcnow()), 'w') as f_out:\n",
    "    json.dump(history.history, f_out)\n",
    "print('Metrics on validation set:\\n------------------------------------------------------------\\n')\n",
    "pred = model.predict(images_val, verbose=0)\n",
    "print(\"Spearman's Correlation CoÃ«fficient: \", spearmanr(pred, labels_val[:,1])[0])\n",
    "plotLearningCurve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.hist(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(labels_val[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
